import torch
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import os
import numpy as np

# Configuration - IMPORTANT: This section is updated for robust local path handling.

# Dynamically get the directory of the current script (e.g., C:\Users\sgonti\Documents\AgenticAI\src)
script_dir = os.path.dirname(os.path.abspath(__file__))

# Go one level up to the project root (e.g., C:\Users\sgonti\Documents\AgenticAI)
project_root = os.path.dirname(script_dir)

# Now, construct the path to 'AgentAI_Data' assuming it's directly under the project root.
# os.path.join will use the correct OS-specific path separators automatically.
AGENT_AI_DATA_ROOT = os.path.join(project_root, "AgentAI_Data")
# Applying the path structure from the fine_tune_codebert.py script
DRIVE_TRAINED_MODELS_PATH = os.path.join(AGENT_AI_DATA_ROOT, "trained_models")
TRAINED_MODEL_PATH = os.path.join(DRIVE_TRAINED_MODELS_PATH, "final_model")

MODEL_NAME = "microsoft/codebert-base" # This remains the Hugging Face model ID for the tokenizer

# FastAPI app instance
app = FastAPI(
    title="Code Vulnerability Detector",
    description="API for detecting code vulnerabilities using a fine-tuned CodeBERT model."
)

# Global variables to store model and tokenizer
tokenizer = None
model = None
device = None

# Pydantic model for request body
class CodeInput(BaseModel):
    code_snippet: str

@app.on_event("startup")
async def startup_event():
    """
    Load the tokenizer and model when the FastAPI application starts up.
    """
    global tokenizer, model, device
    print("Loading tokenizer and fine-tuned model...")
    try:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # Always load tokenizer from Hugging Face Hub (MODEL_NAME)
        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

        # Check if the TRAINED_MODEL_PATH exists before trying to load
        if not os.path.exists(TRAINED_MODEL_PATH):
            print(f"Error: Trained model directory not found at {TRAINED_MODEL_PATH}.")
            print("Please ensure your 'AgentAI_Data' folder (containing 'trained_models/final_model')")
            print(f"is located at: {AGENT_AI_DATA_ROOT}")
            raise FileNotFoundError(f"Trained model directory not found: {TRAINED_MODEL_PATH}")
        # Load the fine-tuned model from the local path on your machine
        model = AutoModelForSequenceClassification.from_pretrained(TRAINED_MODEL_PATH)
        model.to(device)
        model.eval() # Set model to evaluation mode
        print(f"Model loaded successfully from {TRAINED_MODEL_PATH} on device: {device}")
    except FileNotFoundError as fnfe:
        raise HTTPException(status_code=500, detail=f"Failed to load AI model: {fnfe}")
    except Exception as e:
        print(f"Error loading model or tokenizer: {e}")
        raise HTTPException(status_code=500, detail=f"An unexpected error occurred during model loading: {e}")
@app.post("/analyze-code/")
async def analyze_code(input: CodeInput):
    """
    Analyzes a given code snippet for vulnerabilities using the fine-tuned CodeBERT model.
    Returns 1 if vulnerable, 0 if not vulnerable.
    """
    if tokenizer is None or model is None:
        raise HTTPException(status_code=503, detail="AI model not loaded. Please try again later.")

    code_snippet = input.code_snippet

    if not code_snippet:
        raise HTTPException(status_code=400, detail="Code snippet cannot be empty.")

    try:
        # Tokenize the input code
        inputs = tokenizer(
            code_snippet,
            return_tensors="pt",
            truncation=True,
            max_length=512,
            padding=True
        ).to(device)

        # Perform inference
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits

        # Get prediction (0 or 1)
        prediction = torch.argmax(logits, dim=1).item()

        # Map integer prediction to meaningful label
        vulnerability_status = "Vulnerable" if prediction == 1 else "Not Vulnerable"

        return {
            "code_snippet": code_snippet,
            "prediction_raw": prediction,
            "vulnerability_status": vulnerability_status,
            "confidence_scores": logits.softmax(dim=1).tolist()[0]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error during code analysis: {e}")

if __name__ == "__main__":
    import uvicorn
    print("This script is meant to be run with uvicorn directly.")
    print("Example: uvicorn src.vulnerability_api:app --reload")

